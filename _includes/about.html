<section id="research" class="new-section scroll-reveal">
    <div class="publications-wrapper">
    <h2>Research</h2>
    <div class="pub-container">
        <a href="/assets/files/youtube.png" target="_blank" rel="noopener noreferrer" >
            <img src="/assets/files/youtube.png" loading="lazy" alt="Results from the Analysis of Youtube videos cited in research" class="pub_image"></a>
        <div class="content">
            <div class="heading" onclick="window.location.href='https://link.springer.com/article/10.1007/s11192-022-04574-5';">YouTube and Science: Models for Research Impact</div>
            <div class="subheading"> Abdul Rahman Shaikh, Hamed Alhoori, and M. Sun; Journal of Scientometrics, 2023.</div>
            <div class="abstract" id="abstract-text">
                <p>Abstract: Video communication has been rapidly increasing over the past decade, with YouTube providing a medium where users can post, discover, share, and react to videos. There has also been an increase in the number of videos citing research articles, especially since it has become relatively commonplace for academic conferences to require video submissions. However, the relationship between research articles and YouTube videos is not clear, and the purpose of the present paper is to address this issue. We created new datasets using YouTube videos and mentions of research articles on various online platforms. We found that most of the articles cited in the videos are related to medicine and biochemistry. We analyzed these datasets through statistical techniques and visualization, and built machine learning models to predict (1) whether a research article is cited in videos, (2) whether a research article cited in a video achieves a level of popularity, and (3) whether a video citing a research article becomes popular. The best models achieved F1 scores between 80% and 94%. According to our results, research articles mentioned in more tweets and news coverage have a higher chance of receiving video citations. We also found that video views are important for predicting citations and increasing research articlesâ€™ popularity and public engagement with science.</p>
            </div>
            <span class="show-more" onclick="toggleAbstract(this)">Show more</span>
            <div class="key" style="display: flex; align-items: center;">
            <div class="keywords" style="display: flex; align-items: center; gap: 10px;">
                <strong>Keywords:</strong> YouTube, Machine Learning, Altmetrics <strong>Tools:</strong> Python, Tableau, MATLAB
                <a href="https://link.springer.com/content/pdf/10.1007/s11192-022-04574-5.pdf" target="_blank">
                <img src="/assets/files/pdf_icon.png" alt="PDF Icon" style="height:auto; width:18px;"></a>
                <a href="https://link.springer.com/content/pdf/10.1007/s11192-022-04574-5.pdf" target="_blank">PDF</a>
            </div>
            </div>
        </div>
    </div>
        <div class="pub-container">
            <a href="/assets/files/layout.png" target="_blank" rel="noopener noreferrer">
                <img src="/assets/files/layout.png" loading="lazy" alt="Layout Designs proposed in our research" class="pub_image"></a>
            <div class="content">
                <div class="heading" onclick="window.location.href='https://ieeexplore.ieee.org/abstract/document/9973209';">Toward systematic design considerations of organizing multiple views</div>
                <div class="subheading">Abdul Rahman Shaikh, David Koop, Hamed Alhoori, and Maoyuan Sun; IEEE VIS, 2022</div>
                <div class="abstract" id="abstract-text">
                    <p>Abstract: Multiple-view visualization (MV) has been used for visual analytics in various fields (e.g., bioinformatics, cybersecurity, and intelligence analysis). Because each view encodes data from a particular per-spective, analysts often use a set of views laid out in 2D space to link and synthesize information. The difficulty of this process is impacted by the spatial organization of these views. For instance, connecting information from views far from each other can be more challenging than neighboring ones. However, most visual analysis tools currently either fix the positions of the views or completely delegate this organization of views to users (who must manually drag and move views). This either limits user involvement in managing the layout of MV or is overly flexible without much guidance. Then, a key design challenge in MV layout is determining the factors in a spatial organization that impact understanding. To address this, we review a set of MV-based systems and identify considerations for MV layout rooted in two key concerns: perception, which considers how users perceive view relationships, and content, which considers the relationships in the data. We show how these allow us to study and analyze the design of MV layout systematically.</p>                </div>
                <span class="show-more" onclick="toggleAbstract(this)">Show more</span>
                <div class="key" style="display: flex; align-items: center;">
                    <div class="keywords" style="display: flex; align-items: center; gap: 10px;">
                        <strong>Keywords:</strong>Visual Analytics, Layout Design, Multiple views<strong>Tools:</strong> JavaScript, Node.js, Power BI
                        <a href="https://arxiv.org/pdf/2207.07558" target="_blank">
                            <img src="/assets/files/pdf_icon.png" alt="PDF Icon" style="height:auto; width:18px;">
                          </a>
                          <a href="https://arxiv.org/pdf/2207.07558" target="_blank">PDF</a>
                    </div>
                </div>
            </div>
        </div>
        <div class="pub-container">
            <a href="/assets/files/sightbi.png" target="_blank" rel="noopener noreferrer">
                <img src="/assets/files/sightbi.png" loading="lazy" alt="Performing an analysis task with SightBi" class="pub_image"></a>
            <div class="content">
                <div class="heading" onclick="window.location.href='https://ieeexplore.ieee.org/abstract/document/9555226/'">SightBi: Exploring Cross-View Data Relationships with Biclusters</div>
                <div class="subheading">Maoyuan Sun, Abdul Rahman Shaikh, Hamed Alhoori, and Jian Zhao; IEEE Transactions on Visualization and Computer Graphics, 2021 (Best Paper Honorable Mention) </div>
                <div class="abstract" id="abstract-text">
                    <p>Abstract: Multiple-view visualization (MV) has been heavily used in visual analysis tools for sensemaking of data in various domains (e.g., bioinformatics, cybersecurity and text analytics). One common task of visual analysis with multiple views is to relate data across different views. For example, to identify threats, an intelligence analyst needs to link people from a social network graph with locations on a crime-map, and then search for and read relevant documents. Currently, exploring cross-view data relationships heavily relies on view-coordination techniques (e.g., brushing and linking), which may require significant user effort on many trial-and-error attempts, such as repetitiously selecting elements in one view, and then observing and following elements highlighted in other views. To address this, we present SightBi, a visual analytics approach for supporting cross-view data relationship explorations. We discuss the design rationale of SightBi in detail, with identified user tasks regarding the use of cross-view data relationships. SightBi formalizes cross-view data relationships as biclusters, computes them from a dataset, and uses a bi-context design that highlights creating stand-alone relationship-views. This helps preserve existing views and offers an overview of cross-view data relationships to guide user exploration. Moreover, SightBi allows users to interactively manage the layout of multiple views by using newly created relationship-views. With a usage scenario, we demonstrate the usefulness of SightBi for sensemaking of cross-view data relationships.</p>                </div>
                <span class="show-more" onclick="toggleAbstract(this)">Show more</span>
                <div class="key" style="display: flex; align-items: center;">
                    <div class="keywords" style="display: flex; align-items: center; gap: 10px;">
                        <strong>Keywords:</strong> Visual Analysis, Data Visualization, Biclustering <strong>Tools:</strong> JavaScript, Node.js, D3, CSS
                        <a href="https://arxiv.org/pdf/2108.01044" target="_blank">
                        <img src="/assets/files/pdf_icon.png" alt="PDF Icon" style="height:auto; width:18px;"></a>
                        <a href="https://arxiv.org/pdf/2108.01044" target="_blank">PDF</a>
                    </div>
                </div>
            </div>
        </div>     

        <div class="pub-container">
            <a href="/assets/files/longterm.png" target="_blank" rel="noopener noreferrer">
                <img src="/assets/files/longterm.png" loading="lazy" alt="Long Term Impact Results image" class="pub_image"></a>
            <div class="content">
                <div class="heading" onclick="window.location.href='https://www.sciencedirect.com/science/article/abs/pii/S1751157722000402'">Quantifying the online long-term interest in research</div>
                <div class="subheading">Murtuza Shahzad, Hamed Alhoori, Reva Freedman, and Abdul Rahman Shaikh; Journal of Informetrics, 2022 </div>
                <div class="abstract" id="abstract-text">
                    <p>Abstract: Research articles are being shared in increasing numbers on multiple online platforms. Although the scholarly impact of these articles has been widely studied, the online interest determined by how long the research articles are shared online remains unclear. Being cognizant of how long a research article is mentioned online could be valuable information to the researchers. In this paper, we analyzed multiple social media platforms on which users share and/or discuss scholarly articles. We built three clusters for papers, based on the number of yearly online mentions having publication dates ranging from the year 1920 to 2016. Using the online social media metrics for each of these three clusters, we built machine learning models to predict the long-term online interest in research articles. We addressed the prediction task with two different approaches: regression and classification. For the regression approach, the Multi-Layer Perceptron model performed best, and for the classification approach, the tree-based models performed better than other models. We found that old articles are most evident in the contexts of economics and industry (i.e., patents). In contrast, recently published articles are most evident in research platforms (i.e., Mendeley) followed by social media platforms (i.e., Twitter).</p>
                </div>
                <span class="show-more" onclick="toggleAbstract(this)">Show more</span>
                <div class="key" style="display: flex; align-items: center;">
                    <div class="keywords" style="display: flex; align-items: center; gap: 10px;">
                        <strong>Keywords:</strong> Machine Learning, Scholarly Impact, Altmetrics, Regression analysis <strong>Tools:</strong> Python, R, Tableau
                        <a href="https://arxiv.org/pdf/2209.06212" target="_blank">
                            <img src="/assets/files/pdf_icon.png" alt="PDF Icon" style="height:auto; width:18px;"></a>
                        <a href="https://arxiv.org/pdf/2209.06212" target="_blank">PDF</a>
                    </div>
                </div>
            </div>
        </div>        

        <div class="pub-container">
            <a href="/assets/files/policy.png" target="_blank" rel="noopener noreferrer">
                <img src="/assets/files/policy.png" loading="lazy" alt="Youth in Policy Documents study architecture image" class="pub_image"></a>
            <div class="content">
                <div class="heading" onclick="window.location.href='https://arxiv.org/abs/2501.07858'">Examining the Representation of Youth in the US Policy Documents through the Lens of Research                </div>
                <div class="subheading">Miftahul Jannat Mokarrama, Abdul Rahman Shaikh, and Hamed Alhoori; IEEE BigData , 2024 </div>
                <div class="abstract" id="abstract-text">
                    <p>Abstract: This study explores the representation of youth in US policy documents by analyzing how research on youth topics is cited within these policies. The research focuses on three key questions: identifying the frequently discussed topics in youth research that receive citations in policy documents, discerning patterns in youth research that contribute to higher citation rates in policy, and comparing the alignment between topics in youth research and those in citing policy documents. Through this analysis, the study aims to shed light on the relationship between academic research and policy formulation, highlighting areas where youth issues are effectively integrated into policy and contributing to the broader goal of enhancing youth engagement in societal decision-making processes.</p>
                </div>
                <span class="show-more" onclick="toggleAbstract(this)">Show more</span>
                <div class="key" style="display: flex; align-items: center;">
                    <div class="keywords" style="display: flex; align-items: center; gap: 10px;">
                        <strong>Keywords:</strong> NLP, Topic Modeling, Policy Documents <strong>Tools:</strong> Python, R, Tableau
                        <a href="https://arxiv.org/pdf/2209.06212" target="_blank">
                            <img src="/assets/files/pdf_icon.png" alt="PDF Icon" style="height:auto; width:18px;"></a>
                        <a href="https://arxiv.org/pdf/2209.06212" target="_blank">PDF</a>
                    </div>
                </div>
            </div>
        </div>

        <div class="pub-container">
        <a href="/assets/files/patent.png" target="_blank" rel="noopener noreferrer">
            <img src="/assets/files/patent.png" loading="lazy" alt="Results of classification models on patent related data" class="pub_image"></a>
        <div class="content">
            <div class="heading" onclick="window.location.href='https://ieeexplore.ieee.org/abstract/document/8791120/'">Predicting patent citations to measure economic impact of scholarly research</div>
            <div class="subheading">Abdul Rahman Shaikh, and Hamed Alhoori;  ACM/IEEE Joint Conference on Digital Libraries, 2019 </div>
            <div class="abstract" id="abstract-text">
                <p>Abstract: A crucial goal of funding research and development has always been to advance economic development. On this basis, a considerable body of research undertaken with the purpose of determining what exactly constitutes economic impact and how to accurately measure that impact has been published. Numerous indicators have been used to measure economic impact, although no single indicator has been widely adapted. Based on patent data collected from Altmetrics we predict patent citations through various social media features using several classification models. Patents citing a research paper implies the potential it has for direct application in its field. These predictions can be utilized by researchers in determining the practical applications for their work when applying for patents.</p>            </div>
            <span class="show-more" onclick="toggleAbstract(this)">Show more</span>
            <div class="key" style="display: flex; align-items: center;">
                <div class="keywords" style="display: flex; align-items: center; gap: 10px;">
                    <strong>Keywords:</strong> Machine Learning, Economic Impact, Patent Citations <strong>Tools:</strong> Python, R, Tableau
                    <a href="https://arxiv.org/pdf/1906.08244" target="_blank">
                        <img src="/assets/files/pdf_icon.png" alt="PDF Icon" style="height:auto; width:18px;"></a>
                    <a href="https://arxiv.org/pdf/1906.08244" target="_blank">PDF</a>
                </div>
            </div>
        </div>
    </div><div class="pub-container">
        <a href="/assets/files/thesis.png" target="_blank" rel="noopener noreferrer">
            <img src="/assets/files/thesis.png" loading="lazy" alt="Long Term Impact Results image" class="pub_image"></a>
        <div class="content">
            <div class="heading" onclick="window.location.href='https://search.proquest.com/openview/d2f17782f4f4135c177d5656fe062e3e/1?pq-origsite=gscholar&cbl=18750&diss=y'">Modeling the Broader Impact of Science and Health Using Social Media</div>
            <div class="subheading">Abdul Rahman Shaikh, Master's Thesis; Northern Illinois University, 2022 </div>
            <div class="abstract" id="abstract-text">
                <p>Abstract: Research and development have always initiated innovation and breakthroughs in technology. These technological advancements in recent years have provided a global medium for research to be disseminated through online platforms. These web-based platforms and the interactions that take place on them affect the dissemination, impact, and perception of online information. This thesis investigates the broader impact of science and health using social media posts, online patents, videos, and images by building machine learning and topic models. First, this study predicts patent citations to scientific research and identifies important factors essential to economic impact. We found that the citation of research in patents is a strong indicator of economic impact and strengthens the popularity of scholarly research. Second, we studied video communication of scholarly research and found that it has been increasing and there is a lack of studies in this area. Therefore, this study bridges the gap between scientific videos and research by building models to predict videosâ€™ scholarly and societal impact. Finally, this study aims to understand the impact of health-related topics on the public. Instagram images with textual features express different views on topics from usersâ€™ perspectives worldwide. We built topic models on the posts related to health and COVID-19 to analyze users' perceptions across different locations. The thesis identifies factors essential in recognizing the broader influence of science and health. Based on the results, we will have a better understanding of the economic and societal impact of science and the public understanding of health.</p>            </div>
            <span class="show-more" onclick="toggleAbstract(this)">Show more</span>
            <div class="key" style="display: flex; align-items: center;">
                <div class="keywords" style="display: flex; align-items: center; gap: 10px;">
                    <strong>Keywords:</strong> Machine Learning, Computer Vision, Societal Impact, Altmetric <strong>Tools:</strong> Python, TensorFlow
                    <a href="https://search.proquest.com/openview/d2f17782f4f4135c177d5656fe062e3e/1?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">
                        <img src="/assets/files/pdf_icon.png" alt="PDF Icon" style="height:auto; width:18px;"></a>
                    <a href="https://search.proquest.com/openview/d2f17782f4f4135c177d5656fe062e3e/1?pq-origsite=gscholar&cbl=18750&diss=y" target="_blank">PDF</a>
                </div>
            </div>
        </div>
    </div>
    </div>
</section>



<script>
    function toggleAbstract(button) {
        // Get the parent container of the clicked button
        const container = button.closest('.pub-container');

        // Find the abstract-text within this specific container
        const abstract = container.querySelector(".abstract");
        const showMore = container.querySelector(".show-more");

        if (abstract.classList.contains('collapsed')) {
            abstract.classList.remove('collapsed');
            abstract.classList.add('expanded');
            showMore.textContent = "Show less";
            abstract.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
        } else {
            abstract.classList.remove('expanded');
            abstract.classList.add('collapsed');
            showMore.textContent = "Show more";
        }
    }

    // Initialize all abstracts as collapsed when the page loads
    document.addEventListener('DOMContentLoaded', function() {
        const abstracts = document.querySelectorAll('.abstract');
        abstracts.forEach(abstract => {
            abstract.classList.add('collapsed');
        });

        // Add intersection observer for animation on scroll
        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        }, { threshold: 0.1 });

        // Observe all containers
        document.querySelectorAll('.pub-container').forEach(container => {
            container.style.opacity = '0';
            container.style.transform = 'translateY(20px)';
            observer.observe(container);
        });
    });

    class ScrollReveal {
        constructor(options = {}) {
            this.options = {
                threshold: options.threshold || 0.1,
                rootMargin: options.rootMargin || '0px',
                repeat: options.repeat || false,
                hideDelay: options.hideDelay || 1000 // 5 seconds delay
            };

            this.observer = new IntersectionObserver(this.callback.bind(this), {
                threshold: this.options.threshold,
                rootMargin: this.options.rootMargin
            });

            this.elements = document.querySelectorAll('.scroll-reveal');
            this.timeouts = new Map(); // Store timeouts for each element
            this.init();
        }

        init() {
            this.elements.forEach(element => {
                this.observer.observe(element);
            });
        }

        callback(entries) {
            entries.forEach(entry => {
                const element = entry.target;

                if (entry.isIntersecting) {
                    // Clear any existing timeout for this element
                    if (this.timeouts.has(element)) {
                        clearTimeout(this.timeouts.get(element));
                        this.timeouts.delete(element);
                    }
                    element.classList.add('show');

                    if (!this.options.repeat) {
                        this.observer.unobserve(element);
                    }
                } else if (this.options.repeat) {
                    // Instead of removing immediately, set a timeout
                    if (!this.timeouts.has(element)) {
                        const timeout = setTimeout(() => {
                            element.classList.remove('show');
                            this.timeouts.delete(element);
                        }, this.options.hideDelay);

                        this.timeouts.set(element, timeout);
                    }
                }
            });
        }

        destroy() {
            this.timeouts.forEach(timeout => clearTimeout(timeout));
            this.timeouts.clear();
        }
    }

    // Initialize
    const scrollReveal = new ScrollReveal({
        threshold: 0.1,
        repeat: true,
        hideDelay: 500 // 5 seconds
    });


</script>